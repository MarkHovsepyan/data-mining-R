{
    "collab_server" : "",
    "contents" : "# The following dataset consist of data on football games for 11\n# european countries.  It covers time from 2011-2016. The variable\n# result has two arguments: HDW- Home team didnt win, HW- Homw\n# team won. Most of the data describes the players strength\n# averaged for the last 7 games (prior to the given game) averaged\n# by the team (those are only for players who participated in the\n# game).  More information can be found here-\n# http://sofifa.com/player/192883.  You can find a huge amount of\n# analytics done on football data\n# here-https://www.kaggle.com/hugomathien/soccer variables\n# 'home_team_points', 'away_team_points' show the amount of the\n# points the teams have earned before the game (3 for win, 1 for\n# draw, 0 for lose) Variable stage shows the Round number during\n# the season. The poitive case for the model is HW (home team\n# won).\n\n## libraries that may be needed\nlibrary(lattice)\nlibrary(ggplot2)\nlibrary(e1071)\nlibrary(caret)\nlibrary(ROCR)\nlibrary(caTools)\nlibrary(class)\nlibrary(randomForest)\nlibrary(AUCRF)\n\n# Dont forget to set the seed everytime you run randomForest.\n# Divide data into training and testing set,80% goes to train.\n\nload(\"Soccer.rda\")\nset.seed(2016)\nindex <- createDataPartition(soccer$result1, p=0.8, list=F)\ntrain <- soccer[index,]\ntest <- soccer[-index,]\n\n# Question 1. Do some descriptive analytics (charts, tests, etc)\n# to find interesting patterns in the data (10 points)\n\nsummary(soccer$result1)\n## HDW - 10589  and HW - 8800\n## Most of the teams tend to win at home\n\npairs(home_balance ~ home_strength, data = soccer) # balance/strength correlation for home\npairs(away_balance ~ away_strength, data = soccer) # balance/strength correlation for away\n\nqplot(home_potential, data = soccer, binwidth = 0.8) # the concentration is between 70 and 80, pretty high numbers\nqplot(home_heading_accuracy, data = soccer, binwidth = 0.8) # the concentration is between 55 and 65\nqplot(away_heading_accuracy, data = soccer, binwidth = 0.8) # the concentration is between 55 and 70, it is clearly better\n# so home heading accuracy is worse than away heading accuracy.\n\n## data has too many variables, so we divide\ncor(soccer[, 1:35])\ncor(soccer[, 36:71])\n\n## home potential is highly correlated with home short passing, home ball control, home reactions\n## away vision is is highly correlated with awal short passing, away long passing, ball control\n\n# Question 2. Build a\n# random forest model with the package randomForest. Your goal is\n# to predict the game result (variable 'result1') (15 points)\n\nset.seed(2016)\nmodel_rf1 <- randomForest(result1 ~ ., data = train, ntree = 1000, \n                          nodesize = 40, mtry = 5, maxnodes = 20, importance = T, \n                          do.trace = T, localImp = T, replace = F)\n\npred1 <- predict(model_rf1, newdata = test)\npred1_prob <- predict(model_rf1, newdata = test, type = \"prob\") # predicted probabilities\npred1_prob\nconfusionMatrix(pred1, test$result1, positive = \"HW\") # accuracy = 0.6314\nvarImpPlot(model_rf1, sort = T, type = 1, n.var = 40) \n\n# 2.1 Develop randomForest model by tunning several parameters.\n# Look for package help for more info.  Explain the meaning of\n# each parameter.\n\n## ntree: Number of trees to grow.\n## nodesize: This is the minimum node size, it implicitly sets the depth of your trees.\n## mtry: Number of variables randomly sampled as candidates at each split.\n## replace: being false means that we want model without replacement of cases\n## importance: the importance of predictors is being computed\n## do.trace: is a stoping criterea in case the error remains the same and the tree grows\n\nset.seed(2016)\nmtry_tune <- tuneRF(soccer[, -72], soccer[, 72], stepFactor = 1.5, \n                 trace = TRUE, ntreeTry = 500, improve = 0.1, plot = TRUE, doBest = TRUE)\n\nset.seed(2016)\nmodel_rf2 <- randomForest(result1 ~ ., data = train, ntree = 500, \n                          nodesize = 80, mtry = 8, maxnodes = 40, importance = T, \n                          do.trace = T, localImp = T, replace = F) # this configuration seems to be quite good\n\n\n# 2.2 Report on accuracy of your final chosen model (OOB\n# estimate). Comment on it\n\npred2 <- predict(model_rf2, newdata = test)\nconfusionMatrix(pred2, test$result1, positive = \"HW\")\n## accuracy is 0.6428\n\n\nprint(model_rf2)\n##OOB estimate is 35.36%\n\n## this accuracy is not the highest possible, but it is the best I could get by simply tuning the parameters\n## nodesize of 80 seems a bit too high but, it works well, maxnodes = 40 seems to give the best cut for the trees,\n## and the mtry that I got trough tuneRF function is the one that gives the minimal error among those which I tried\n\n# 2.3 Report AUC on testing set.\n\npred2_prob <- predict(model_rf2, newdata = test, type = \"prob\")\npred_final <- prediction(pred2_prob[, 2], test$result1, label.ordering = c(\"HDW\", \"HW\"))\nperf_final <- performance(pred_final, \"tpr\", \"fpr\")\nplot(perf_final)\nperformance(pred_final, \"auc\")@y.values #auc= 0.6940419\n\n# 2.4 What are the most important variables?\n\nvarImpPlot(model_rf2, sort = T, type = 1, n.var = 40)\n\n## let's say the most important ones are the following\n## away_ball_control, away_vision, home_short_passing, home_ball_control, away_potential\n\n# Question 3. Use caret to train randomforest model. Think about\n# the hyperparameters you can use for model tuning.  Do grid\n# search.Hint: play with expand.grid parameter.  Report the best\n# model. (15 points).\n\nset.seed(2016)\ncontrol <- trainControl(method = \"repeatedcv\", number = 10, repeats = 3, search = \"grid\")\ntunegrid <- expand.grid(.mtry=c(sqrt(ncol(train))))\nmodellist <- list()\n\nset.seed(2016)\nfit <- train(result1 ~ ., data = train, method = \"rf\", metric='Accuracy', \n             tuneGrid = tunegrid, trControl = control)\n\nprint(rf_gridsearch)\nplot(rf_gridsearch)\n\n## This took more than 2 hours on my i7 pc and I still feel like Hachiko :) it didn't finish\n## but I guess this is correct way\n\n# Question 4. there is a package 'AUCRF' that uses randomForest\n# but reports AUC on the OOB sets.  Use it to build randomforest\n# model (10 points)\n\naucrf_train <- train # to make changes to the result1 (make 0/1)\naucrf_train$result1 <- factor(aucrf_train$result1, levels=c('HDW', 'HW'), labels = c(0,1))\n\nset.seed(2016)\nmodel_aucrf <- AUCRF(result1 ~ ., data = aucrf_train, ranking=\"MDA\")\nplot(model_aucrf)\nsummary(model_aucrf) # AUC of selected variables: OOB-AUCopt= 0.7046464 \n\n\n# Bonus question (15 points). \n# The variables in the dataset are the\n# same measures of home and away teams. For example\n# 'away_short_passing' and 'home_short_passing' are showing how\n# good are both teams in short passing. Now think what kind of\n# transformations can you do with the data to decrease the number\n# of variables and get better model. Report your way of thinking\n# and the final model.\n\n## So if there are symmetric variables\n## I think that taking the averages for each column and making 2 variables 1 is a nice opportunity\n## I think of a trick, where I can remove the first part of the string and get the names of the variables generalized\n## I expect to get a huge decrease in the accuracy, as this way is making data less informative\n\nsoccer_new <- soccer[, c(1:3,72)]\nsoccer_columns <- colnames(soccer)\n\n# starting column indeces for home/away variables\ni_home = 4 \ni_away = 38\n\nrepeat { \n  if (i_home <= 37) \n  { \n    home_cols <- soccer_columns[i_home]\n    away_cols <- soccer_columns[i_away]\n    \n    columns_final <- substr(home_cols, 6, nchar(home_cols)) # generalizing the variable name\n    soccer_new[[columns_final]] <- (soccer[[home_cols]] + soccer[[away_cols]])/2\n    \n    i_home = i_home + 1 # no increment operator :(\n    i_away = i_away + 1\n  }\n  else{break}\n}\n\nset.seed(2016)\nindex <- createDataPartition(soccer_new$result1, p = 0.8, list = FALSE)\ntrain_final <- soccer_new[index,]\ntest_final <- soccer_new[-index,]\n\nset.seed(2016)\nmodel_rf_final <- randomForest(result1 ~ ., data = train_final, ntree = 500, \n                          nodesize = 80, mtry = 8, maxnodes = 40, importance = T, \n                          do.trace = T, localImp = T, replace = F)\n\npred_final <- predict(model_rf_final, newdata = test_final)\nconfusionMatrix(pred_final, test_final$result1, positive = \"HW\")\n## Accuracy = 0.5798\n## It's low, as I was expecting\n",
    "created" : 1481032638954.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "697806767",
    "id" : "207FFF8E",
    "lastKnownWriteTime" : 1481036448,
    "last_content_update" : 1481036448590,
    "path" : "D:/Programming/R/Homework 9/Mark_Hovsepyan_HW_9.R",
    "project_path" : "Mark_Hovsepyan_HW_9.R",
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}