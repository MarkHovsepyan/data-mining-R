View(cluster_mean)
boxplot(GCI_csv$Pillar.2 ~ GCI_csv$cluster_membership)
set.seed(5)
km <- kmeans(GCI_csv[, -1], 4)
km$iter
names(km)
GCI_csv$km_cluster <- km$cluster
table(GCI_csv$cluster_membership, GCI_csv$km_cluster)
WDI_csv <- read.csv("WDI.csv")
WDI_csv$km_cluster <- GCI_csv$km_cluster # using k-means clustering
View(WDI_csv)
aggregate(WDI_csv, by = list(WDI_csv$km_cluster), FUN = "max", na.rm = TRUE)
aggregate(WDI_csv[, -1], by = list(WDI_csv$km_cluster), FUN = "max", na.rm = TRUE)
aggregate(WDI_csv[, -1], by = list(WDI_csv$km_cluster), FUN = "min", na.rm = TRUE)
GPI_csv <- read.csv("GPI.csv")
GPI_csv$km_cluster <- GCI_csv$km_cluster # using k-means clustering
View(GPI_csv)
aggregate(GPI_csv$GPI.2016.Score, by = list(GPI_csv$km_cluster), FUN = "mean", na.rm = TRUE)
aggregate(GPI_csv$GPI.2016.Rank, by = list(GPI_csv$km_cluster), FUN = "mean", na.rm = TRUE)
GCI1 <- as.data.frame(scale(GCI_csv[, -1]))
GCI_csv <- read.csv("GCI.csv")
rownames(GCI_csv) <- GCI_csv[, 1]
GCI_csv[, 1] <- NULL
GCI1 <- as.data.frame(scale(GCI_csv[, -1]))
GCI_dist <- dist(GCI1, method = "euclidean") # distances
clust <- hclust(GCI_dist)
plot(clust, labels = FALSE, hang = -1)
plot(clust, labels = FALSE, hang = -1) # ploting clusters
rect.hclust(clust, 3) # take 3 clusters
plot(clust, labels = FALSE, hang = -1) # ploting clusters
rect.hclust(clust, 3) # take 3 clusters
plot(clust, labels = FALSE, hang = -1) # ploting clusters
rect.hclust(clust, 4) # take 3 clusters
plot(clust, labels = FALSE, hang = -1) # ploting clusters
rect.hclust(clust, 8) # take 3 clusters
plot(clust, labels = FALSE, hang = -1) # ploting clusters
rect.hclust(clust, 16) # take 3 clusters
plot(clust, labels = FALSE, hang = -1) # ploting clusters
rect.hclust(clust, 32) # take 3 clusters
plot(clust, labels = FALSE, hang = -1) # ploting clusters
rect.hclust(clust, 64) # take 3 clusters
plot(clust, labels = FALSE, hang = -1) # ploting clusters
rect.hclust(clust, 32) # take 3 clusters
plot(clust, labels = FALSE, hang = -1) # ploting clusters
rect.hclust(clust, 48) # take 48 clusters
GCI_csv$cluster_hierarchical <- cutree(clust, k = 48)
cluster_mean <- aggregate(GCI_csv[, -1], by = list(GCI_csv$cluster_membership), FUN = "mean", na.rm = TRUE)
GCI_csv$cluster_hierarchical <- cutree(clust, k = 48)
cluster_mean <- aggregate(GCI_csv[, -1], by = list(GCI_csv$cluster_membership), FUN = "mean", na.rm = TRUE)
GCI_csv$cluster_hierarchical <- cutree(clust, k = 48)
plot(clust, labels = FALSE, hang = -1) # ploting clusters
rect.hclust(clust, 35) # take 35 clusters
GCI_csv$cluster_hierarchical <- cutree(clust, k = 35)
cluster_mean <- aggregate(GCI_csv[, -1], by = list(GCI_csv$cluster_membership), FUN = "mean", na.rm = TRUE)
GCI_csv$cluster_hierarchical <- cutree(clust, k = 35)
GCI_csv <- read.csv("GCI.csv")
GCI_csv <- read.csv("GCI.csv")
View(GCI_csv)
rownames(GCI_csv) <- GCI_csv[, 1]
GCI_csv[, 1] <- NULL
GCI1 <- as.data.frame(scale(GCI_csv[, -1]))
GCI_dist <- dist(GCI1, method = "euclidean") # distances
clust <- hclust(GCI_dist)
plot(clust, labels = FALSE, hang = -1)
plot(clust, labels = FALSE, hang = -1) # ploting clusters
rect.hclust(clust, 3) # take 3 clusters
plot(clust, labels = FALSE, hang = -1) # ploting clusters
rect.hclust(clust, 4) # take 4 clusters
plot(clust, labels = FALSE, hang = -1) # ploting clusters
rect.hclust(clust, 8) # take 8 clusters
plot(clust, labels = FALSE, hang = -1) # ploting clusters
rect.hclust(clust, 16) # take 16 clusters
plot(clust, labels = FALSE, hang = -1) # ploting clusters
rect.hclust(clust, 32) # take 32 clusters
plot(clust, labels = FALSE, hang = -1) # ploting clusters
rect.hclust(clust, 64) # take 64 clusters
plot(clust, labels = FALSE, hang = -1) # ploting clusters
rect.hclust(clust, 35) # take 35 clusters
GCI_csv$cluster_hierarchical <- cutree(clust, k = 35)
cluster_mean <- aggregate(GCI_csv[, -1], by = list(GCI_csv$cluster_membership), FUN = "mean", na.rm = TRUE)
cluster_mean <- aggregate(GCI_csv[, -1], by = list(GCI_csv$cluster_hierarchical), FUN = "mean", na.rm = TRUE)
View(cluster_mean)
boxplot(ClusterMeans$Pillar.7)
boxplot(cluster_mean$Pillar.7)
boxplot(cluster_mean$Pillar.7 ~ GCI_csv$cluster_membership)
plot(clust, labels = FALSE, hang = -1) # ploting clusters
rect.hclust(clust, 48) # take 48 clusters
GCI_csv$cluster_hierarchical <- cutree(clust, k = 48)
cluster_mean <- aggregate(GCI_csv[, -1], by = list(GCI_csv$cluster_hierarchical), FUN = "mean", na.rm = TRUE)
View(cluster_mean)
boxplot(GCI_csv$Pillar.10 ~ GCI_csv$cluster_hierarchical)
summary(cluster_mean)
table(row.names(GCI_csv), GCI_csv$km)
set.seed(5)
km <- kmeans(GCI_csv[, -1], 48)
km$iter
names(km)
GCI_csv$km_cluster <- km$cluster
GCI_csv$km_cluster <- km$cluster
table(row.names(GCI_csv), GCI_csv$km)
table(GCI_csv$cluster_membership, GCI_csv$km_cluster)
table(GCI_csv$cluster_hierarchical, GCI_csv$km_cluster)
aggregate(WDI_csv[, -1], by = list(WDI_csv$km_cluster), FUN = "max", na.rm = TRUE)
WDI_csv <- read.csv("WDI.csv")
View(WDI_csv)
WDI_csv$km_cluster <- GCI_csv$km_cluster # using k-means clustering
aggregate(WDI_csv$Population, by = list(WDI_csv$km_cluster), FUN = "max", na.rm = TRUE)
aggregate(WDI_csv$Population, by = list(WDI_csv$km_cluster), FUN = "min", na.rm = TRUE)
wdi_pop_min <- aggregate(WDI_csv$Population, by = list(WDI_csv$km_cluster), FUN = "min", na.rm = TRUE)
wdi_pop_max <- aggregate(WDI_csv$Population, by = list(WDI_csv$km_cluster), FUN = "max", na.rm = TRUE)
soccer <- read.csv("Soccer.csv")
View(soccer)
summary(wdi_pop_min)
summary(wdi_pop_max)
View(wdi_pop_min)
ClustUneploymentMean <- aggregate(WDI$SL.UEM.TOTL.ZS, by = list(WDI_csv$km_cluster), FUN="mean", na.rm = TRUE)
ClustGDPPerCapitaMean <-aggregate(WDI$NY.GDP.PCAP.CD, by = list(WDI_csv$km_cluster), FUN="mean", na.rm = TRUE)
ClustUneploymentMean <- aggregate(WDI_csv$SL.UEM.TOTL.ZS, by = list(WDI_csv$km_cluster), FUN="mean", na.rm = TRUE)
ClustUneploymentMean <- aggregate(WDI_csv$Unemployment, by = list(WDI_csv$km_cluster), FUN="mean", na.rm = TRUE)
ClustGDPPerCapitaMean <-aggregate(WDI_csv$GDP_per_.capita, by = list(WDI_csv$km_cluster), FUN="mean", na.rm = TRUE)
summary(ClustGDPPerCapitaMean)
summary(ClustUneploymentMean)
View(ClustGDPPerCapitaMean)
View(ClustUneploymentMean)
View(soccer)
soccer1 <- as.data.frame(scale(soccer[, -c(1, 2, 3)]))
soccer_dist <- dist(soccer1, method = "euclidean") # distances
clust1 <- hclust(soccer_dist)
soccer_dist <- dist(soccer1, method = "euclidean") # distances
soccer_dist <- dist(soccer1, method = "euclidean") # distances
soccer1 <- as.data.frame(scale(soccer[, -c(1, 2, 3)]))
soccer1 <- as.data.frame(scale(soccer[, -c(1, 2, 3, 4)]))
soccer_dist <- dist(soccer1, method = "euclidean") # distances
clust1 <- hclust(soccer_dist)
plot(clust1, labels = FALSE, hang = -1)
plot(clust1, labels = FALSE, hang = -1) # ploting clusters
rect.hclust(clust, 3) # take 3 clusters
plot(clust1, labels = FALSE, hang = -1) # ploting clusters
rect.hclust(clust, 4) # take 4 clusters
plot(clust1, labels = FALSE, hang = -1) # ploting clusters
rect.hclust(clust, 4) # take 4 clusters
plot(clust1, labels = FALSE, hang = -1) # ploting clusters
rect.hclust(clust, 8) # take 8 clusters
plot(clust1, labels = FALSE, hang = -1) # ploting clusters
rect.hclust(clust, 16) # take 16 clusters
plot(clust1, labels = FALSE, hang = -1) # ploting clusters
rect.hclust(clust, 32) # take 32 clusters
plot(clust1, labels = FALSE, hang = -1) # ploting clusters
rect.hclust(clust, 64) # take 64 clusters
plot(clust1, labels = FALSE, hang = -1) # ploting clusters
rect.hclust(clust, 500) # take 64 clusters
plot(clust1, labels = FALSE, hang = -1) # ploting clusters
rect.hclust(clust, 100) # take 64 clusters
WDI_csv <- read.csv("WDI.csv")
View(WDI_csv)
#####Homework 3#####
# ATTENTION!!!: whenever you are applying k means clustering, set seed equal to 5.
# You need to set seed every time before performing k means clustering.
# The Global Competitiveness Report 2015-2016 assesses the competitiveness
# landscape of 144 economies, providing insight into the drivers of their
# productivity and prosperity. The report remains the most comprehensive assessment of
# national competitiveness worldwide, providing a platform for
# dialogue between government, business and civil society about the actions
# required to improve economic prosperity. Competitiveness is defined as the
# set of institutions, policies and factors that determine the level of
# productivity of a country. The level of productivity, in turn, sets the
# level of prosperity that can be earned by an economy.
# Visit http://reports.weforum.org/global-competitiveness-report-2015-2016 for more details
# The different aspects of competitiveness are captured in 12 pillars,
# which compose the Global Competitiveness Index. The value for pillar for each country is a
# number between 1-7 and is measured based on the set of sub-indicators (also measured by the scale 1-7)
# Your task is to create clusters of countries based on the pillars of competitivness.
# 1. Load the dataset GCI.csv into R.
GCI_csv <- read.csv("GCI.csv")
View(GCI_csv)
# 2. Make the variable Country.code as rownames for the dataframe
# (hint: use rownames() command) (1)
?rownames
rownames(GCI_csv) <- GCI_csv[, 1]
# 3. Remove the variable Country.Code from the dataframe as you will
# not need it anymore. (1)
GCI_csv[, 1] <- NULL
# 4. Run hierarchical clustering on the dataset, using 12 pillars as clustering variables (2)
GCI1 <- as.data.frame(scale(GCI_csv[, -1]))
GCI_dist <- dist(GCI1, method = "euclidean") # distances
clust <- hclust(GCI_dist)
plot(clust, labels = FALSE, hang = -1)
# 5.Plot the dendogram. What do you think is the optimal number of clusters?
# Try 4 different options. The code should be written in such a
# way that R gives you a new clear plot each time you try different number
# of clusters and the rectangles are drown on top of them for each of your options.
# Your goal is to get as nit plots as possible. (2)
plot(clust, labels = FALSE, hang = -1) # ploting clusters
rect.hclust(clust, 3) # take 3 clusters
plot(clust, labels = FALSE, hang = -1) # ploting clusters
rect.hclust(clust, 4) # take 4 clusters
plot(clust, labels = FALSE, hang = -1) # ploting clusters
rect.hclust(clust, 8) # take 8 clusters
plot(clust, labels = FALSE, hang = -1) # ploting clusters
rect.hclust(clust, 16) # take 16 clusters
plot(clust, labels = FALSE, hang = -1) # ploting clusters
rect.hclust(clust, 32) # take 32 clusters
plot(clust, labels = FALSE, hang = -1) # ploting clusters
rect.hclust(clust, 64) # take 64 clusters
# 5.1 Choose one of the numbers of the clusters that you created in problem 5.
# Describe what are the differnces between the clusters in terms of differences in  means. (1)
## we can see that the countries, that are clustered togeter have some sonnections
## although 32 is not sufficent and 64 is too much, we can take the average of those numbers
## which is 48
plot(clust, labels = FALSE, hang = -1) # ploting clusters
rect.hclust(clust, 48) # take 48 clusters
GCI_csv$cluster_hierarchical <- cutree(clust, k = 48)
cluster_mean <- aggregate(GCI_csv[, -1], by = list(GCI_csv$cluster_hierarchical), FUN = "mean", na.rm = TRUE)
View(cluster_mean)
# 5.2 How will you describe your clusters? Try to give names to each of the clusters.(1)
## I'll try to classify some of the clusters accoring to their geo-political similarities
## 23'rd cluster includes RUS, CHN.
## These countries share a political(sociliastic) and economical connections
## 28'th cluster includes NOR, DNK(Denmark),LUX, SWE,QAT, ARE
## This are mainly nordic countries except for two of them, but all of these countries are alike
## in their foreign investment strategies and revenue generation.
## These countries can be called "Nordlike Investors"
## 29'th cluster includes GUY, ZMB, GHA, DOM, HND
## These are African and American countries(and Carribean pool) that
## share similar history and development patterns(economical,political).
## These countries can be called "Afro - American"
## 40'th cluster includes USA, GBR, JPN.
## These are post modernized and post industrialized countries
## that are one the top of world technological, inovative and finacial force.
## These countries can be called "Rich Inovators"
## 42'nd cluster includes only KOR (south Korea)
## This is an expected outcome, as South Korea is an isolated country
## The other clusters are also combining quite similar countries,
## mostly by their geographical, historical, financial aspects, though it is hard to classify them
# 5.3 Looking at the averages of the pillars for each cluster, pick a pillar
# that you think constitutes the largest difference between the clusters.
# Create a boxplot of that pillar against the clusters. Give your comments. (2)
summary(cluster_mean) # pillar 10 has the largest differences
boxplot(GCI_csv$Pillar.10 ~ GCI_csv$cluster_hierarchical)
# 6.Run K-means algorithm, with the same number of clusters that you used in the
# prevous problem. (1)
set.seed(5)
km <- kmeans(GCI_csv[, -1], 48)
km$iter ## itterates 2 times
GCI_csv$km_cluster <- km$cluster
# 7. Are the results the same? Comment.
# (Remember that you might get different numbers (labels) for the
# clusters if you are using different methods. (2)
table(GCI_csv$cluster_hierarchical, GCI_csv$km_cluster)
## the numbers(labels) of clusters are changed, but the contents of the clusters remain
## fairly alike. The clusters are not perfectly the same, though numerous
## similarities can be observed.
# Now choose one of the methods and continue with that.
## I choose k-means
# The dataset WDI indicators has some social and economic data on the countries included in GCI study.
# Note the WDI dataset has the same order as GCI,
# so you can easly add cluster variable to the WDI dataset
# 8.1 Read the dataset into R. Look at the population - what are the min and max values
# for each cluster? what does this info tell you about the clusters? (2)
WDI_csv <- read.csv("WDI.csv")
View(WDI_csv)
WDI_csv$km_cluster <- GCI_csv$km_cluster # using k-means clusters on this dataframe
wdi_pop_max <- aggregate(WDI_csv$Population, by = list(WDI_csv$km_cluster), FUN = "max", na.rm = TRUE)
wdi_pop_min <- aggregate(WDI_csv$Population, by = list(WDI_csv$km_cluster), FUN = "min", na.rm = TRUE)
summary(wdi_pop_min)
summary(wdi_pop_max)
View(wdi_pop_min)
View(wdi_pop_max)
##
##
# 8.2 Describe your clusters using indicators from the WDI dataset:
# Note that the meanings of the variables are given in a seperate file.
# You need to do a small research, if you want to understand better these variables.
# Try to give description of each cluster in 2-3 sentences. (3)
ClustUneploymentMean <- aggregate(WDI_csv$Unemployment, by = list(WDI_csv$km_cluster), FUN="mean", na.rm = TRUE)
ClustGDPPerCapitaMean <-aggregate(WDI_csv$GDP_per_.capita, by = list(WDI_csv$km_cluster), FUN="mean", na.rm = TRUE)
summary(ClustGDPPerCapitaMean)
summary(ClustUneploymentMean)
View(ClustGDPPerCapitaMean)
View(ClustUneploymentMean)
## In cluster 28, having the minumum unemployment of all the clusters and their
## GDP per capta is the higest among all of the clusters. Their economical infrastructure is great.
## In cluster 40, though being developed in their infastructure
## the unemployment rates are quite average. Still those rates are impressive in
## comparison to the whole world 6,7 ~= 6,3 < 9,126. The  overal GDP is in best triple of the dateset.
## In cluster 23, though having unemployment rates that
## are in TOP 5 of the overal dataset, their GDP Per capita is lower than the average of the datestet.
## In cluster 29, though the uneployment rates in these countries
## are quite average the GDP Per Capita is one of the lowest in the dataset.
## This indicates the fact of having low and cheap productions.
# Global Peace Index is an attempt to measure the relative position of nations' and regions' peacefulness.
# The dataset GPI provides the Global Peace Index scores and rankings
# for the countries included in the list.
# Note the GPI dataset has the same order as GCI,
# so you can easly add cluster variable to the WDI dataset.
# 9.1 Load the dataset into R.
GPI_csv <- read.csv("GPI.csv")
View(GPI_csv)
# 9.2 Calcualte average score for each cluster. Comment on your findings. (2)
GPI_csv$km_cluster <- GCI_csv$km_cluster # using k-means clustering
aggregate(GPI_csv$GPI.2016.Score, by = list(GPI_csv$km_cluster), FUN = "mean", na.rm = TRUE)
# 9.3 Estimate rankings for cluster based on the average scores you received in previous step.
# (The rankings for each country are available in the GPI dataset.)(2)
aggregate(GPI_csv$GPI.2016.Rank, by = list(GPI_csv$km_cluster), FUN = "mean", na.rm = TRUE)
cor()
# 10. Do your own research on the datasets, find something interesting.(5)
# Do not do trivial manipulations like creating plots without making any valuable
# inferences about those plots.
#Football data analysis
# The file Soccer.csv summarized various data for football players from 11 European
# Leagues. The data is collecting based on the FIFA ratings.
# http://sofifa.com/player/192883 By opening this link, you can find the data for
# Henrikh Mkhitaryan, as well as find the decriptions of the variables. Do some
# reasearch on this web site before starting your homework.
# 11. Load file Soccer.csv into R. Perform k means clustering.
# Try with at least two different numbers of clusters. (2)
soccer <- read.csv("Soccer.csv")
View(soccer)
# 12. Plot the clusters for all the trials (numbers of clusters).
# Do you see any similarity in both graphs?
# Hint: you may find useful package fpc and function called plotcluster. (3)
# 13. Aggregate the means for all the variables for one of
# the results that you got in question 2. Give comments about the clusters. (2)
# 14. Now perform hierarchical clustering. Again try with several number of clusters. (2)
# 15. For all the trials, again create plots and try to find patterns.
# Describe the patterns that you noticed. (2)
# 16. Based on the patterns and similarities between the graphs that you
# noticed while performing clustering with kmeans and hierarchical
# clustering, come up with an optimal number of clusters. Choose
# either of the clustering methods, and assign clusters to each of
# the cases in the soccer dataset. (2)
# 17. Aggregate the average data for all the variables for the number
# of the clusters that you chose in question 7. What are the differences
# between those clusters? Try to give a general description for 5-6 of them. (2)
# 18. Pick a player from each of those clusters. Describe those players in terms of
# their affiliation to the clusters. What are the similarities and differences between them? (1)
# 19. Now aggregate the data in a way that you end up with dataframe
# where each row represents a club. Now run clustering on that dataframe
# (use whichever method you prefer.) Aggregate the average values for
# each of the clusters. Again, choose 5-6 variables, compare the clubs
# based on them, and try to give names to the clusters.
# 20. Do your own research on the datasets, find something interesting.
# Do not do trivial manipulations like creating plots without making any valuable
# inferences about those plots. (5)
summary(wdi_pop_min)
summary(wdi_pop_max)
aggregate(WDI_csv$Population, by = list(WDI_csv$km_cluster), FUN = "max", na.rm = TRUE)
View(wdi_pop_min)
max(wdi_pop_max$x)
which.max(wdi_pop_max$x)
which.mean(wdi_pop_max$x)
which.min(wdi_pop_max$x)
which.min(wdi_pop_min$x)
View(wdi_pop_max)
which.min(wdi_pop_min$x)
which.max(wdi_pop_max$x)
library(ggplot2)
qplot(GPI.2016.Rank, GPI.2016.Score, data = GPI_csv, xlab = "Ranking", ylab = "Score")
cor(GPI$GPI.2016.Score, GPI$GPI.2016.Rank)
cor(GPI_csv$GPI.2016.Score, GPI_csv$GPI.2016.Rank)
which.max(GPI_csv$GPI.2016.Score)
GPI_csv[127,]                      # Ukraine
which.min(GPI_csv$GPI.2016.Score)
GPI_csv[52,]                       # Iceland
which.max(GPI_csv$GPI.2016.Rank)
GPI_csv[132,]                      # Thailand
which.min(GPI_csv$GPI.2016.Rank)
GPI_csv[52,]                       # Hong Kong
GPI_csv[54,]                       # Hong Kong
which.max(GPI_csv$GPI.2016.Score)
GPI_csv[132,]                      # Ukraine
which.max(GPI_csv$GPI.2016.Rank)
GPI_csv[132,]                      # Ukraine
which.max(GPI_csv$GPI.2016.Score)
GPI_csv[132,]                      # Ukraine
which.min(GPI_csv$GPI.2016.Score)
GPI_csv[54,]                       # Iceland
which.min(GPI_csv$GPI.2016.Rank)
which.min(GPI_csv$GPI.2016.Rank)
which.max(GPI_csv$GPI.2016.Score)
which.max(GPI_csv$GPI.2016.Rank)
GPI_csv[132,]                      # Ukraine
View(GPI_csv)
cor(GPI_csv$GPI.2016.Score, GPI_csv$GPI.2016.Rank, use="complete.obs")
getwd()
soccer<-read.csv("Soccer.csv", header = TRUE)
summary(soccer)
set.seed(5)
k1 <- kmeans(Zscore, 3)
k1 <- kmeans(soccer1, 3)
k2 <- kmeans(soccer1, 4)
k3 <- kmeans(soccer1, 5)
k4 <- kmeans(soccer1, 8)
soccer1 <- as.data.frame(scale(soccer[,5:42]))
set.seed(5)
k1 <- kmeans(soccer1, 3)
k2 <- kmeans(soccer1, 4)
k3 <- kmeans(soccer1, 5)
k4 <- kmeans(soccer1, 8)
install.packages("fpc")
plotcluster(soccer1, k1$cluster)
plotcluster(soccer1, k1$cluster)
library(fpc)
plotcluster(soccer1, k1$cluster)
plotcluster(soccer1, k2$cluster)
plotcluster(soccer1, k3$cluster)
plotcluster(soccer1, k4$cluster)
k4 <- kmeans(soccer1, 30)
plotcluster(soccer1, k4$cluster)
k4 <- kmeans(soccer1, 8)
plotcluster(soccer1, k4$cluster)
plotcluster(soccer1, k3$cluster)
plotcluster(soccer1, k2$cluster)
plotcluster(soccer1, k1$cluster)
plotcluster(soccer1, k2$cluster)
plotcluster(soccer1, k1$cluster)
plotcluster(soccer1, k2$cluster)
plotcluster(soccer1, k2$cluster)
soccer_kmeans_cluster <- k1$cluster # let's take 3 clusters
aggregate(soccer[,5:42], by=list(soccer_kmeans_cluster), FUN="mean", na.rm=TRUE)
View(soccer_kmeans_cluster)
summary(soccer_kmeans_cluster)
km$iter ## itterates 2 times
distance <- dist(soccer1, method="euclidean")
cluster_Soccer<-hclust(distance)
rm(cluster_Soccer)
soccer_hier_cluster <- hclust(distance)
rect.hclust(soccer_hier_cluster, k=2)
plot(cluster_Soccer, hang=-1)
plot(soccer_hier_cluster, hang=-1)
plot(soccer_hier_cluster, hang=-1, labels = FALSE)
rect.hclust(soccer_hier_cluster, k=2)
plot(soccer_hier_cluster, hang=-1, labels = FALSE)
rect.hclust(soccer_hier_cluster, k=2)
plot(soccer_hier_cluster, hang=-1, labels = FALSE)
rect.hclust(soccer_hier_cluster, k=3)
plot(soccer_hier_cluster, hang=-1, labels = FALSE)
rect.hclust(soccer_hier_cluster, k=4)
plot(soccer_hier_cluster, hang=-1, labels = FALSE)
rect.hclust(soccer_hier_cluster, k=5)
plot(soccer_hier_cluster, hang=-1, labels = FALSE)
rect.hclust(soccer_hier_cluster, k=3)
rect.hclust(soccer_hier_cluster, k=4)
plot(soccer_hier_cluster, hang=-1, labels = FALSE)
rect.hclust(soccer_hier_cluster, k=4)
aggregate(soccer[,5:42], by = list(soccer_kmeans_cluster), FUN="mean", na.rm=TRUE)
clubs <- aggregate(soccer, by=list(soccer$team_short_name), FUN="mean",na.rm=TRUE)
summary(club)
clubs <- aggregate(soccer, by=list(soccer$team_long_name), FUN="mean",na.rm=TRUE)
warnings()
clubs <- aggregate(soccer, by=list(soccer$team_long_name), FUN="mean", na.rm=TRUE)
rm(clubs)
clubs <- aggregate(soccer, by = list(soccer$team_long_name), FUN="mean", na.rm=TRUE)
summary(club)
summary(clubs)
club_dist <- dist(clubs[,5:42], method="euclidean")
club_cluster <- hclust(club_dist)
plot(club_cluster, hang = -1, labels = FALSE)
rect.hclust(club_cluster, k=3)
club_clustering <- cutree(club_cluster, k=3)
aggregate(club[,14:42],by=list(club_cluster_1), FUN="mean", na.rm=TRUE)
aggregate(club[,14:42], by = list(club_clustering), FUN="mean", na.rm=TRUE)
aggregate(clubs[,14:42], by = list(club_clustering), FUN="mean", na.rm=TRUE)
pairs(~ Age + aggression + heading_accuracy + stamina, data = soccer) #age
cor(Age~)
cor(Age~.)
plotcluster(soccer1, k1$cluster)
cor(soccer$Age, use = "complete.obs")
View(soccer)
cor(soccer[, 5], use = "complete.obs")
cor(soccer[, 6], use = "complete.obs")
cor(soccer[, Age], use = "complete.obs")
pairs(~ Age + aggression + heading_accuracy + stamina, data = soccer)
soccer[1517,]
soccer[Henrik Mkhitaryan,]
soccer[c(Henrik Mkhitaryan),]
aggregate(clubs[,14:42], by = list(club_clustering), FUN="mean", na.rm=TRUE)
aggregate(soccer[,5:42], by=list(soccer_kmeans_cluster), FUN="mean", na.rm=TRUE)
soccer$kmeans_cluster <- k1$cluster
soccer[913,"kmeans_cluster"] # Alejandro Bedoya
soccer[913,"player_name"]
soccer[3124,"Clust_member"]
soccer[3124,"Clust_member"]
soccer[3124,"player_name"] # Joao Palinha
sample(nrow(soccer), 3)
soccer[2076,"kmeans_cluster"] # Alejandro Bedoya
soccer[2076,"player_name"]
soccer[1792,"kmeans_cluster"]
soccer[2163,"player_name"] # Germano Vailati
soccer[2076,"kmeans_cluster"] # Alejandro Bedoya
soccer[1792,"kmeans_cluster"]
soccer[2163,"kmeans_cluster"] # The third given number by Set.seed is not from cluster 3 so I chose by my own.
soccer[4420,"kmeans_cluster"] # The third given number by Set.seed is not from cluster 3 so I chose by my own.
soccer[4419,"kmeans_cluster"] # The third given number by Set.seed is not from cluster 3 so I chose by my own.
soccer[44118,"kmeans_cluster"] # The third given number by Set.seed is not from cluster 3 so I chose by my own.
soccer[4418,"kmeans_cluster"] # The third given number by Set.seed is not from cluster 3 so I chose by my own.
soccer[4452,"kmeans_cluster"] # The third given number by Set.seed is not from cluster 3 so I chose by my own.
soccer[3001,"kmeans_cluster"] # The third given number by Set.seed is not from cluster 3 so I chose by my own.
soccer[3001,"player_name"] # Germano Vailati
soccer[2076,"player_name"]
soccer[1792,"player_name"] # Joao Palinha
soccer[3001,"player_name"] # Germano Vailati
soccer[2076,"kmeans_cluster"]
soccer[1792,"kmeans_cluster"]
soccer[2076,]
soccer[1792,]
soccer[3001,]
soccer[2076,]
soccer[1792,]
soccer[3001,]
cor(soccer)
cor(soccer[,5:42])
