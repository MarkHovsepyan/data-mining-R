scoring <- read.csv <- ("Scoring.csv")
library(caret)
scoring <- read.csv <- ("Scoring.csv")
scoring <- read.csv("Scoring.csv")
View(scoring)
index <- createDataPartition(scoring$default, p = .8, list = FALSE)
scoring <- read.csv("Scoring.csv")
index <- createDataPartition(scoring$default, p = .8, list = FALSE)
library(e1071)
library(caret)
library(caTools)
library(ROCR)
index <- createDataPartition(scoring$default, p = .8, list = FALSE)
install.packages("caret")
library(caret)
scoring <- read.csv("Scoring.csv")
index <- createDataPartition(scoring$default, p = .8, list = FALSE)
Train <- spam[index,]
Test <- spam[-index,]
Train <- scoring[index,]
Test <- scoring[-index,]
set.seed(2016)
index <- createDataPartition(scoring$default, p = .8, list = FALSE)
Train <- scoring[index,]
Test <- scoring[-index,]
credit <- read.csv("Credit.csv")
View(credit)
credit$default <- factor(credit$default,
levels = c(0,1),labels = c("Not Defaulted","Defaulted"))
credit$default <- ordered(credit$default,
levels = c(0,1),labels = c("Not Defaulted","Defaulted"))
credit <- read.csv("Credit.csv")
credit$default <- order(credit$default,
levels = c(0,1),labels = c("Not Defaulted","Defaulted"))
credit$default <- factor(credit$default,
levels = c(0,1),labels = c("Not Defaulted","Defaulted"))
set.seed(2016)
index <- createDataPartition(scoring$default, p = .8, list = FALSE)
Train <- credit[index,]
Test <- credit[-index,]
set.seed(2016)
index <- createDataPartition(scoring$default, p = .8, list = FALSE)
index <- createDataPartition(credit$default, p = .8, list = FALSE)
Train <- credit[index,]
Test <- credit[-index,]
nb_model <- naiveBayes(default~., data = Train, laplace = 1)
pred_test <- predict(nb_model, newdata = Test)
confusionMatrix(pred_test, Test$default, positive = "Defaulted")
perf <- performance(pred_test, "tpr", "fpr")
perf <- performance(predictions, "tpr", "fpr")
nb_model <- naiveBayes(default~., data = Train, laplace = 1)
pred_test <- predict(nb_model, newdata = Test)
pred_test_new <- predict(nb_model, newdata = Test, type = "raw")
predictions <- prediction(pred_test_prob_spam[, 1], Test$is_spam, label.ordering = c("Yes", "No"))
confusionMatrix(pred_test, Test$default, positive = "Defaulted")
nb_model <- naiveBayes(default~., data = Train, laplace = 1)
pred_test <- predict(nb_model, newdata = Test)
pred_test_new <- predict(nb_model, newdata = Test, type = "raw")
predictions <- prediction(pred_test_prob_spam[, 1], Test$is_spam, label.ordering = c("Yes", "No"))
nb_model <- naiveBayes(default~., data = Train, laplace = 1)
pred_test <- predict(nb_model, newdata = Test)
pred_test_new <- predict(nb_model, newdata = Test, type = "raw")
predictions <- prediction(pred_test_prob_spam[, 1], Test$default, label.ordering = c("Defaulted", "Not Defaulted"))
pred_test_new <- predict(nb_model, newdata = Test, type = "raw")
predictions <- prediction(pred_test_new[, 1], Test$default, label.ordering = c("Defaulted", "Not Defaulted"))
confusionMatrix(pred_test, Test$default, positive = "Defaulted")
perf <- performance(predictions, "tpr", "fpr")
plot(perf)
performance(predictions, "auc")@y.values
plot(perf, col = rainbow(10)))
plot(perf, col = rainbow(10))
plot(perf, col = rainbow(2))
plot(perf, col = rainbow(0))
plot(perf, col = rainbow(15))
plot(perf)
performance(predictions, "auc")@y.values
nb_model$tables
nb_model$levels
nb_model$apriori
nb_model$call
nb_model$tables
rm(list = ls())
library(unvotes)
library(dplyr)
library(magrittr)
library(wordcloud)
library(ggplot2)
library(tm)
library(lubridate)
library(SnowballC)
votes<-un_votes
armenia<-votes%>%filter(country=="Armenia")
summary(armenia$vote)
abstentions <- votes %>% filter(country!="Zanzibar")%>%
mutate("abstain" = ifelse(as.character(vote) == "abstain", 1, 0)) %>%
group_by(country) %>%
summarise("prct_abstentions" = sum(abstain)/n_distinct(rcid)) %>%
arrange(desc(prct_abstentions))
abstentions[1:10, ] %>% as.data.frame
j<- votes %>% inner_join(un_roll_calls, by = "rcid")
armdata<-j%>%inner_join(un_roll_call_issues, by="rcid")
armdata<-armdata%>%filter(date>'1992-01-01', country!="Zanzibar")
abstentionsarm <- armdata %>%
mutate("abstain" = ifelse(as.character(vote) == "abstain", 1, 0)) %>%
group_by(country) %>%
summarise("prct_abstentions" = sum(abstain)/n_distinct(rcid)) %>%
arrange(desc(prct_abstentions))
abstentionsarm[1:10, ] %>% as.data.frame
abstentionsarm[32,]
un_agree <- function(db, # the database
country1,    country2,abstain = TRUE # if FALSE, do not count abstains
){
c1 <- db %>%
filter(country == country1) %>%
mutate("vote2" = vote)
c2 <- db %>%
filter(country == country2)
j <- c1 %>% select(vote2, rcid) %>%
left_join(., c2 %>% select(rcid, vote), by = "rcid") %>%
filter(!is.na(vote))
if(!abstain){
j <- j %>%
filter(vote != "abstain") %>%
filter(vote2 != "abstain")
}
j <- j %>%
mutate("agree" = ifelse(vote2 == as.character(vote), 1, 0))
sum(j$agree)/length(j$agree)*100
}
wa<- function(db, country_pivot)
{
v <- NULL
for(i in 1:length(unique(db$country))){
country <- unique(db$country)[i]
p <- un_agree(db = votes,
country1 = country_pivot,
country2 = unique(db$country)[i])
d <- data.frame("country" = country, "p" = p)
v <- rbind.data.frame(v, d)}
return(v)
}
wa(armdata, "Armenia") %>%
arrange(desc(p)) %>%
filter(country != "Armenia" ) %>% #p=100 for Armenia
head()
wa(armdata, "Armenia") %>%
arrange(desc(p)) %>%
filter(country != "Armenia") %>%  tail()
wa(armdata, "Armenia") %>%
arrange(desc(p)) %>%
filter(country != "Armenia" ) %>% #p=100 for Armenia
head()
wa(armdata, "Armenia") %>%
arrange(desc(p)) %>%
filter(country != "Armenia") %>%  tail()
wa(armdata, "Armenia") %>%
arrange(desc(p)) %>%
filter(country != "Armenia") %>%  tail()
wa(armdata, "Armenia") %>%
arrange(desc(p)) %>%
filter(country != "Armenia" ) %>% #p=100 for Armenia
head()
wa(armdata, "Armenia") %>%
arrange(desc(p)) %>%
filter(country != "Armenia") %>%  tail()
armagree<-c(un_agree(armdata, "Armenia", "Russian Federation"),
un_agree(armdata, "Armenia", "Turkey"),
un_agree(armdata,"Armenia","Georgia"),
un_agree(armdata, "Armenia", "France"))
vals <-as.character(round(armagree,digits=1))
agr<-barplot(armagree, main="Percentage of Agreement with Armenia", names.arg = c("Russia","Turkey","Georgia", "France"))
text(agr,vals, labels=vals, pos=3)
text(agr,vals, labels=vals, pos=3)
un_agree(armdata, "Russian Federation", "United States")
un_agree(armdata, "Russian Federation", "Azerbaijan")
armdata %<>% mutate("armpres" = ifelse(date >= '1992-01-01' & date <= '1998-02-03', "Ter-Petrosyan",
ifelse(date >= '1998-02-04' &    date <= '2008-04-09', "Kocharyan",
ifelse(date >= '2008-04-10' & date <= '2018-11-30', "Sargsyan", "Other"))))
armus<-c(un_agree(armdata %>% filter(armpres =="Ter-Petrosyan"),  "Armenia", "United States"),
un_agree(armdata %>% filter(armpres =="Kocharyan"),  "Armenia", "United States"),
un_agree(armdata %>% filter(armpres=="Sargsyan"),  "Armenia", "United States"))
vals <-as.character(round(armus,digits=1))
b2<-barplot(armus, main="Armenia & USA", names.arg = c("Ter-Petrosyan","Kocharyan","Sargsyan"))
text(b2,vals, labels=vals, pos=3)
armrus<-c(un_agree(armdata %>% filter(armpres =="Ter-Petrosyan"),  "Armenia", "Russian Federation"),
un_agree(armdata %>% filter(armpres =="Kocharyan"),  "Armenia", "Russian Federation"),
un_agree(armdata %>% filter(armpres =="Sargsyan"),  "Armenia", "Russian Federation"))
vals <-as.character(round(armrus,digits=1))
b1<-barplot(armrus, main="Armenia & Russia", names.arg = c("Ter-Petrosyan","Kocharyan","Sargsyan"))
text(b1,vals, labels=vals, pos=3)
armaz<-c(un_agree(armdata %>% filter(armpres =="Ter-Petrosyan"),  "Armenia", "Azerbaijan"),
un_agree(armdata %>% filter(armpres =="Kocharyan"),  "Armenia", "Azerbaijan"),
un_agree(armdata %>% filter(armpres =="Sargsyan"),  "Armenia", "Azerbaijan"))
vals <-as.character(round(armaz,digits=1))
b3<-barplot(armaz, main="Armenia & Azerbaijan", names.arg = c("Ter-Petrosyan","Kocharyan","Sargsyan"))
text(b3,vals, labels=vals, pos=3)
agree_by_term <- armdata %>%
filter(country %in% c("Armenia","Russian Federation")) %>%
group_by(year = year(date), rcid) %>%
summarise("DifVote" = n_distinct(vote)) %>%
mutate("Agree" = ifelse(DifVote == 1, 1, 0)) %>%
summarise("PercentageAgree" = sum(Agree)/n_distinct(rcid),
"VoteCount" = n_distinct(rcid))
agree_by_term<-agree_by_term[agree_by_term$year>1991,]
pres.RF<-ts(agree_by_term$PercentageAgree,frequency=1, start=1992)
plot(pres.RF, xaxt="n", main="Armenia & Russia", xlab="Presidents",ylab="Agreement")
axis(1,at=1992:1992 ,labels="Boris Yeltsin")
axis(1,at=1998:1998, labels="Vladimir Putin")
axis(1,at=2008:2008, labels="Dmitri Medvedev")
axis(1,at=2012:2012, labels="Vladimir Putin")
agree_by_termUSA<-armdata %>%
filter(country %in% c("Armenia", "United States")) %>%
group_by(year = year(date), rcid) %>%
summarise("DifVote" = n_distinct(vote)) %>%
mutate("Agree" = ifelse(DifVote == 1, 1, 0)) %>%
summarise("PercentageAgree" = sum(Agree)/n_distinct(rcid),
"VoteCount" = n_distinct(rcid))
agree_by_termUSA<-agree_by_termUSA[agree_by_termUSA$year>1991,]
pres.USA<-ts(agree_by_termUSA$PercentageAgree,deltat=1, start=1992)
pres.USA<-ts(agree_by_termUSA$PercentageAgree,deltat=1, start=1992)
plot(pres.USA, xaxt="n", main="Armenia & USA", xlab="Presidents",ylab="Agreement")
axis(1,at=1993:1993 ,labels="Bill Clinton")
axis(1,at=2001:2001, labels="George W. Bush")
axis(1,at=2009:2009, labels="Barack Obama")
armiss<-armdata%>%filter(country=="Armenia")
tbl<-table(armiss$issue, armiss$vote)
tbl
no<-armiss%>%filter(issue=="Human rights", vote=="no")
tbl1<-table(armdata$importantvote, armdata$vote)
tbl1
chisq.test(tbl1)
tbl2<-table(armiss$armpres, armiss$vote)
tbl2
chisq.test(tbl2)
tbl3<-table(armdata$issue, armdata$vote)
tbl3
chisq.test(tbl3)
cname <- file.path("~", "Desktop", "texts")
cname
dir(cname)
descr <- Corpus(DirSource(cname))
summary(descr)
descr <- tm_map(descr, removePunctuation)
descr<-tm_map(descr,removeNumbers)
descr<-tm_map(descr, tolower)
descr <- tm_map(descr, removeWords, stopwords("english"))
descr <- tm_map(descr, stripWhitespace)
set.seed(1997)
wordcloud(names(freq), freq, min.freq=300, scale=c(5, .1), colors=brewer.pal(6, "Dark2"))
dark2 <- brewer.pal(6, "Dark2")
wordcloud(names(freq), freq, max.words=100, rot.per=0.2, colors=dark2)
credit <- read.csv("Credit.csv")
credit_data$ed <- as.factor(credit_data$ed)
credit_data$default <- as.factor(credit_data$default)
credit$default <- factor(credit$default,
levels = c(0,1),labels = c("Not Defaulted","Defaulted"))
credit <- read.csv("Credit.csv")
credit$ed <- as.factor(credit$ed)
credit$default <- as.factor(credit$default)
credit$default <- factor(credit$default,
levels = c(0,1),labels = c("Not Defaulted","Defaulted"))
set.seed(2016)
index <- createDataPartition(credit$default, p = .8, list = FALSE)
Train <- credit[index,]
Test <- credit[-index,]
library(e1071)
library(caret)
library(caTools)
library(ROCR)
credit <- read.csv("Credit.csv")
credit$ed <- as.factor(credit$ed)
credit$default <- as.factor(credit$default)
credit$default <- factor(credit$default,
levels = c(0,1),labels = c("Not Defaulted","Defaulted"))
set.seed(2016)
index <- createDataPartition(credit$default, p = .8, list = FALSE)
Train <- credit[index,]
Test <- credit[-index,]
nb_model <- naiveBayes(default~., data = Train, laplace = 1)
pred_test <- predict(nb_model, newdata = Test)
pred_test_prob <- predict(nb_model, newdata = Test, type = "raw")
predictions <- prediction(pred_test_prob[, 1], Test$default, label.ordering = c("Defaulted", "Not Defaulted"))
confusionMatrix(pred_test, Test$default, positive = "Defaulted")
perf <- performance(predictions, "tpr", "fpr")
plot(perf, colorize = TRUE)
performance(predictions, "auc")@y.values
model
nb_model
scoring_predict <- predict(nb_model, newdata = scoring, type="raw")
scoring <- read.csv("Scoring.csv")
scoring_predict <- predict(nb_model, newdata = scoring, type="raw")
scoring$default <- scoring_predict[, 2]
scoring_predict <- predict(nb_model, newdata = scoring, type = "raw")
scoring$default <- scoring_predict[, 2]
least_risky_25 <- head(scoring[order(scoring$default, decreasing= FALSE),], n = nrow(scoring_data)/4)
least_risky_25 <- head(scoring[order(scoring$default, decreasing= FALSE),], n = nrow(scoring)/4)
average_age <- mean(top_25_least_risky$age)
scoring <- read.csv("Scoring.csv")
scoring_predict <- predict(nb_model, newdata = scoring, type = "raw")
scoring$default <- scoring_predict[, 2]
library(e1071)
library(caret)
library(caTools)
library(ROCR)
credit <- read.csv("Credit.csv")
credit$ed <- as.factor(credit$ed)
credit$default <- as.factor(credit$default)
credit$default <- factor(credit$default,
levels = c(0,1),labels = c("Not Defaulted","Defaulted"))
set.seed(2016)
index <- createDataPartition(credit$default, p = .8, list = FALSE)
Train <- credit[index,]
Test <- credit[-index,]
nb_model <- naiveBayes(default~., data = Train, laplace = 1)
pred_test <- predict(nb_model, newdata = Test)
pred_test_prob <- predict(nb_model, newdata = Test, type = "raw")
predictions <- prediction(pred_test_prob[, 1], Test$default, label.ordering = c("Defaulted", "Not Defaulted"))
confusionMatrix(pred_test, Test$default, positive = "Defaulted") # cnofusion matrix
perf <- performance(predictions, "tpr", "fpr")
plot(perf, colorize = TRUE)
nb_model
performance(predictions, "auc")@y.values
scoring <- read.csv("Scoring.csv")
scoring_predict <- predict(nb_model, newdata = scoring, type = "raw")
scoring$default <- scoring_predict[, 2]
leastRisky_25 <- head(scoring[order(scoring$default, decreasing= FALSE),], n = nrow(scoring)/4)
average_age <- mean(leastRisky_25$age)
average_income <- mean(top_25_least_risky$income)
average_age <- mean(leastRisky_25$age)
average_income <- mean(leastRisky_25$income)
table(leastRisky_25$ed)
average_cred_debt <- mean(leastRisky_25$creddebt)
debt_to_income_ratio_average <- mean(leastRisky_25$debtinc)
other_debt_average <- mean(leastRisky_25$othdebt)
print(average_age <- mean(leastRisky_25$age))
print(average_age <- mean(leastRisky_25$age))
print(average_income <- mean(leastRisky_25$income))
print(average_age <- mean(leastRisky_25$age))
print(average_age <- mean(leastRisky_25$age))
print(average_income <- mean(leastRisky_25$income))
print(average_cred_debt <- mean(leastRisky_25$creddebt))
print(debt_to_income_ratio_average <- mean(leastRisky_25$debtinc))
print(average_age <- mean(leastRisky_25$age))
print(average_income <- mean(leastRisky_25$income))
print(average_debt_card <- mean(leastRisky_25$creddebt))
print(debt_income__average <- mean(leastRisky_25$debtinc))
bottomRisky_25 <- tail(scoring[order(scoring$default, decreasing = FALSE),], n = nrow(scoring)/4)
print(averageAge_bottom <- mean(bottomRisky_25$age))
print(averageIncome_bottom <- mean(bottomRisky_25$income))
table(bottom_25_risky$ed)
table(bottomRisky_25$ed)
hist(bottomRisky_25$ed)
table(bottomRisky_25$income)
hist(bottomRisky_25$income)
hist(bottomRisky_25$ed) # education level histogram
table(bottomRisky_25$ed)
table(bottomRisky_25$income)
hist(bottomRisky_25$income) # income amount histogram
table(bottomRisky_25$income, bottomRisky_25$ed)
cor(bottomRisky_25$income, bottomRisky_25$ed)
pairs(bottomRisky_25) # income amount histogram
print(average_debt_card_bottom <- mean(bottomRisky_25$creddebt))
print(debt_income__average_bottom <- mean(bottomRisky_25$debtinc))
print(average_debt_card_bottom <- mean(bottomRisky_25$creddebt))
print(debt_income__average_bottom <- mean(bottomRisky_25$debtinc))
# The dataset credit contains information about the bank customers.
# It is used to identify whether a customer who applied for the
# loan will default or not.
## libraries that may be needed
library(e1071)
library(caret)
library(caTools)
library(ROCR)
#1. Load credit data into R. Make sure the categorical
# variables are factored. Create testing and training
# datasets, so that 80% of data goes to train and the rest
# goes to test. Make sure the proportions of the dependent
# variable are fixed. Set the seed to 2016. (7)
credit <- read.csv("Credit.csv")
credit$ed <- as.factor(credit$ed)
credit$default <- as.factor(credit$default)
credit$default <- factor(credit$default,
levels = c(0,1),labels = c("Not Defaulted","Defaulted"))
set.seed(2016)
index <- createDataPartition(credit$default, p = .8, list = FALSE)
Train <- credit[index,]
Test <- credit[-index,]
#2. Create a naive bayes model on the dataset. Set
# Laplace equal to 1. What is the accuracy of the model? (7)
nb_model <- naiveBayes(default~., data = Train, laplace = 1)
pred_test <- predict(nb_model, newdata = Test)
pred_test_prob <- predict(nb_model, newdata = Test, type = "raw")
predictions <- prediction(pred_test_prob[, 1], Test$default, label.ordering = c("Defaulted", "Not Defaulted"))
confusionMatrix(pred_test, Test$default, positive = "Defaulted") # cnofusion matrix
## Accuracy is 0.741
#3. Plot the ROC curve, make sure you have the colors of the
# thresholds on the curve. Give explanation to the coloring of
# the curve: what does it show?? What is the AUC? (7)
perf <- performance(predictions, "tpr", "fpr")
plot(perf, colorize = TRUE)
performance(predictions, "auc")@y.values
## The area under the curve is 0.7208738
#4. Given that someone defaulted, what is the probability that
# he/she has postgarduate degree? (7)
nb_model
## 0.01315789
#5.Take any of the classification methods that we studied so
# far and build a model using it. Compare that model with the
# Naive Bayes model. Which one does better? Comment. (7)
#6. Load the scoring datset into R. Our goal will be to give
# credit scores (defualting probabilities) to the potential
# customers. Predict the scores with the Naive Bayes model. (8)
scoring <- read.csv("Scoring.csv")
scoring_predict <- predict(nb_model, newdata = scoring, type = "raw")
scoring$default <- scoring_predict[, 2]
#7. Identify the top 25% of customers that are least risky.
# Describe them with the variables you have in the scoring dataset.(7)
leastRisky_25 <- head(scoring[order(scoring$default, decreasing= FALSE),], n = nrow(scoring)/4)
print(average_age_top <- mean(leastRisky_25$age))
print(average_income_top <- mean(leastRisky_25$income))
print(average_debt_card_top <- mean(leastRisky_25$creddebt))
print(debt_income__average_top <- mean(leastRisky_25$debtinc))
table(leastRisky_25$ed)
## Aveerage age = 40.64865~41
## Average income = 54.40541
## Average credit card debt ~ 1097
## Average ratio of debt to income = 7.727027
## data from education degree table
## 1 has high school degree
## 36 people do not have even high school degree
# Bonus point
#8. Compare top 25% of risky customers (Quartile 4) with bottom 25% of risky customers (Quartile 1).
# What are the main differences you see? Generate 1-2 tables and graphs for the analysis. (10 points)
bottomRisky_25 <- tail(scoring[order(scoring$default, decreasing = FALSE),], n = nrow(scoring)/4)
print(averageAge_bottom <- mean(bottomRisky_25$age))
# Average age for bottom 25% = 35.84211 ~ 36 years
print(averageIncome_bottom <- mean(bottomRisky_25$income))
# Average income for bottom 25% ~ 79473
print(average_debt_card_bottom <- mean(bottomRisky_25$creddebt))
# Average credit card debt ~ 3472
print(debt_income__average_bottom <- mean(bottomRisky_25$debtinc))
# Average ratio of debt to income = 12.96316
table(bottomRisky_25$ed)
hist(bottomRisky_25$ed) # education level histogram
## Amazingly high number of people with college degree compared to other education levels
## 2nd most are post-graduate degree people
cor(bottomRisky_25$income, bottomRisky_25$ed)
pairs(bottomRisky_25) # some correlations of variables
table()
table(average_age_top, averageAge_bottom)
nb_model$tables
LDA_model <- lda(Default~., data = Train)
library(klaR)
LDA_model <- lda(Default~., data = Train)
View(Train)
LDA_model <- lda(default~., data = Train)
LDA_pred <- predict(LDA, newdata = Test)
LDA_pred <- predict(LDA_model, newdata = Test)
confusionMatrix(LDA_pred$class, Test$default, positive = "Defaulted")
confusionMatrix(pred_test, Test$default, positive = "Defaulted") # cnofusion matrix
GLM_model <- glm(default~ ., data = Train, family = "binomial")
GLM_pred <- predict(GLM_model, newdata = Test, type = "response")
labels <- ifelse(pred_test_2 > 0.5,"Yes", "No")
labels <- ifelse(GLM_pred > 0.5,"Yes", "No")
confusionMatrix(labels, Test$default, positive = "Yes")
labels <- ifelse(GLM_pred > 0.5, "Yes", "No")
confusionMatrix(labels, Test$default, positive = "Yes")
labels <- ifelse(GLM_pred > 0.5, "Defaulted", "Not Defaulted")
confusionMatrix(labels, Test$default, positive = "Defaulted")
table(leastRisky_25$ed)
