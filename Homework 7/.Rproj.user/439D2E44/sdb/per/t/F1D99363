{
    "collab_server" : "",
    "contents" : "# The dataset credit contains information about the bank customers.\n# It is used to identify whether a customer who applied for the\n# loan will default or not.\n\n#ibrary(caret)\n#(e1071)\n#ibrary(class)\n#ibrary(rpart)\n\n#1. Load credit data into R. Make sure the categorical\n# variables are factored. Create testing and training \n# datasets, so that 80% of data goes to train and the rest\n# goes to test.Make sure the proportions of the dependent \n# variable are fixed. Set the seed to 2016. (7)\ncredit<-read.csv(\"Credit.csv\")\ncredit$default<-factor(credit$default, levels = c(0,1), labels = c(\"No\", \"Yes\"))\ncredit$ed<-as.ordered(credit$ed)\nset.seed(2016)\n\nTrainIndex<-createDataPartition(credit$default, p=0.8, list = F) \nTrain<-credit[TrainIndex,]\nTest<-credit[-TrainIndex,]  \n\n#2. Create a naive bayes model on the dataset. Set \n# Laplace equal to 1. What is the accuracy of the model? (7)\n#library(e1071)\n#library(ROCR)\nset.seed(2016)\n\nc_model<-naiveBayes(default~., data=Train, laplace = 1)\nc_pred_test<-predict(c_model, newdata = Test)\nconfusionMatrix(c_pred_test, Test$default, positive = \"Yes\")\n#accuracy=0.741\n# Sensitivity          Specificity       Pos Pred Value       Neg Pred Value \n#0.27777778           0.90291262           0.50000000           0.78151261 \n\n\n#3. Plot the ROC curve, make sure you have the colors of the\n# thresholds on the curve. Give explanation to the coloring of\n# the curve: what does it show?? What is the AUC? (7)\nc_pred_test_prob<-predict(c_model, newdata = Test, type=\"raw\")\nc_pred_test_prob\nc_p_test<-prediction(c_pred_test_prob[,2],Test$default, label.ordering = c(\"No\", \"Yes\"))\n#library(ROCR)\nperf<-performance(c_p_test, \"tpr\", \"fpr\")\n#ROC curve color-coded by the threshold \nplot(perf,colorize=T, print.cutoffs.at=seq(0,1,0.1), text.adj=c(-0.2,1.7)) #text.adj just to adjust the text on the chart\nperformance(c_p_test, \"auc\")@y.values #auc=0.7208738\n\n#for different cut off values we will get different tp and fp rates. the coloring gives the thresholds of\n#cut off values e.g. the most simple one:\n#If you have threshold of 1  you will not catch any poor case or have sensitivity of 0,\n#but you will correctly label all good cases, meaning you have false positive rate of 0., tpr=1, fpr=0\n\n\n\n#4. Given that someone defaulted, what is the probability that\n# he/she has postgarduate degree? (7)\n\n\n#P(PD|Defaulted) = P(PD and Defaulted)/P(Defaulted)\nTable<-table(credit$default, credit$ed)\nprop.table(Table)\nc_model$tables$ed\nc_model\n0.001428571/0.2614286   # 0.005464479\n\n# Given that someone defaulted, the probability that he/she has postgarduate degree is 3.903199e-05\n\n#5.Take any of the classification methods that we studied so\n# far and build a model using it. Compare that model with the\n# Naive Bayes model. Which one does better? Comment. (7)\nset.seed(2016)\n\nfit<-rpart(default~., data=Train, method=\"class\")\npred_class<-predict(fit, Test, type=\"class\")\nconfusionMatrix(pred_class, Test$default, positive = \"Yes\")\n\n #accuracy=0.784\n#Sensitivity          Specificity       Pos Pred Value       Neg Pred Value \n#0.6666667            0.8252427            0.5714286            0.8762887 \nset.seed(2016)\n\nmodel2<-glm(default~.,data = Train, family = \"binomial\")\nsummary(model2)\n#better model with significant independant variables\nmodel2<-glm(default~age+employ+address+debtinc+creddebt, data=Train, family = \"binomial\")\n\npred_test_2<-predict(model2, newdata = Test, type = \"response\")\n\nlabels<-ifelse(pred_test_2>0.58,\"Yes\", \"No\")\nconfusionMatrix(labels, Test$default, positive = \"Yes\")\n# Accuracy= 0.82014388\n#Sensitivity          Specificity       Pos Pred Value       Neg Pred Value \n#0.5277778            0.9223301            0.7037037            0.8482143 \n\n#when comparing the 3 models used glm gives the highes accuracy with cut off value 0.58\n#with highest specificity, and medium sensitivity\n#With naiveBayes we get teh lowest accuray since decision tree also gives higher accuracy than \n#naiveBayes\n#1 reason to this may be the fact that with glm we can distinguish the significant independant variables\n#and guess more correctly the dependant one by creating the new model2\n#2nd reason is that with glm we have the highest specificity which means now we have more\n#accurate predictions of tpr as such and less fp rates => better predictions which again comes\n#from the reason1\npred_prob_2<-predict(model2, newdata = Test, type=\"response\")\npred_2<-prediction(pred_prob_2, Test$default)\nperf_2<-performance(pred_2, \"tpr\",\"fpr\")\nperformance(pred_2, \"auc\")@y.values\nplot(perf_2,colorize=T, print.cutoffs.at=seq(0,1,0.1), text.adj=c(-0.2,1.7))\n\n#auc=0.7208738 got higher auc up to 0.793959 with glm with cut off value in the green region\n\n#6. Load the scoring datset into R. Our goal will be to give\n# credit scores (defualting probabilities) to the potential\n# customers. Predict the scores with the Naive Bayes model. (8)\nscoring<-read.csv(\"Scoring.csv\")\npred_scoring <- predict(c_model, newdata = scoring, type = \"raw\")\nscoring$default<- pred_scoring[,2]\n#without probabilities\nscoring<-read.csv(\"Scoring.csv\")\n\nscoring$default<- predict(c_model, scoring, type=\"class\")\n\n#7. Identify the top 25% of customers that are least risky.\n# Describe them with the variables you have in the scoring dataset.(7) \n#in order to get the top risky people we need to have default probabilites \nscoring<-read.csv(\"Scoring.csv\")\npred_scoring <- predict(c_model, newdata = scoring, type = \"raw\")\nscoring$default<- pred_scoring[,2]\n#least 25% risky=1st Qu.\n\nsummary(scoring) #0.0316761 default risk probability of 1st quartile\nsummary(scoring[scoring$default<=0.0316761,]) \nsummary(scoring[scoring$default<=1,]) \n\n#the least risky are those customers that are aged 30-36 in the range of 21-56, that are employed\n#2-10.25 years. with 1st level of educ.(didn't complete high school) which very surprising,\n#that live 0-8 years in the current address,income is 21k-32k, debt to income is 1.3-4.8 (obviously income is higher)\n#credit card debt is the least ranging 0.083k-0.45k, other debts the least 0.25k-1.3k, \n#default risk is the least also when income is from 21k-32k \n\n# Bonus point\n#8. Compare top 25% of risky customers (Quartile 4) with bottom 25% of risky customers (Quartile 1). \n# What are the main differences you see? Generate 1-2 tables and graphs for the analysis. (10 points)\n\n#from point 7 it is obvious that the defaul risk is the least when to debt to income is in the 1st quartile\n#from our summary of glm I saw a important significance of creddebt and debtinc with default\n#but not with other debts, which can be explained by the fact that other debts are not that high\n# and cannot therefore affect the default. \n\n#the top 25% risky are those who have the vice versa sitation compared to least 25% \n#the most surprising factors for high default risk are the high edu. level, income . Can be explained in the way that those who have high income\n# have high debts (because they are emplyed for more than 14 years, have high income and spend more) \n#so that debtinc and creddebt are high\npairs(default~ed+income+age, data=scoring)\ncor(scoring[,c(\"Cust_ID\", \"age\",\"ed\", \"employ\",\"address\",\"income\",\"debtinc\",\"creddebt\",\"othdebt\",\"default\")])\n\n\n# default risk is mostly correlated with edu, the least the edu level the less risk of default\n# because those are the people who take least risky loans from banks for short-term  with low interest rate\n#those with higher income (meaning high ed. level)take more risky long term loans with higher interest rates\n#having high default risk\n\n\n\n\n\n\n\n\n\n\n\n\n",
    "created" : 1479057562648.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3961916434",
    "id" : "F1D99363",
    "lastKnownWriteTime" : 1479056984,
    "last_content_update" : 1479056984,
    "path" : "C:/Users/markh/Desktop/HW7 _mariam.R",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}