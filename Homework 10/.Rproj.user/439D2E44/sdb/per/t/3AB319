{
    "collab_server" : "",
    "contents" : "# The dataset Cancer.csv contains data about the tumor cells\n# for 100 patients. The independent variables are different\n# characteristics of the tumor cells. The dependant variable\n# is diagosis_result, which has two classes: B and M (benign\n# and malignant). Our goal is to create the model to identify\n# whether the patient has type B or type M cancer.\n\n## libraries that may be needed\nlibrary(class)\nlibrary(ROCR)\nlibrary(caret)\nlibrary(neuralnet)\nlibrary(ggplot2)\nlibrary(pROC)\n\n# 1. Load data. Prepare training and testing sets (80%/20%).\n# Make all the required preprocessing for building the\n# neuralnetwork model. (10)\n\ncancer <- read.csv(\"Cancer.csv\")\n\nsc <- function(x) {\n  (x - min(x))/(max(x) - min(x))\n}\n\nfor(x in 1:8) {\n  cancer[, x] <- sc(cancer[, x])\n}\n\ncancer$diagnosis_result <- ifelse(cancer$diagnosis_result == \"M\", 0, ifelse(cancer$diagnosis_result == \"B\", 1, cancer$diagnosis_result))\n\n\nindex <- createDataPartition(cancer$diagnosis_result, p=0.8, list=F)\ntrain <- cancer[index,]\ntest <- cancer[-index,]\n\n\n# 2. Build the neural network model. Play with the parameters\n# in order to get as high accuracy as possible. Report the\n# final accuracy. Plot the model, make sure you do not have\n# overlapping objects in the plot.  (20)\n\nfm <- formula(diagnosis_result ~ radius+texture+perimeter+area+smoothness+compactness+symmetry+fractal_dimension)\n\nmodel_nn <- neuralnet(fm, data = train, hidden = c(3, 4, 3), rep = 7, \n                       linear.output = F, err.fct = \"ce\")\n\nplot(model_nn, length = 0.1)\ncmpt <- compute(model_nn, test[, -9], rep = 1)\np_test <- ROCR::prediction(cmpt$net.result[, 1], test$diagnosis_result)\nperformance(p_test, \"auc\")@y.values\n\nclass_nn <- ifelse(cmpt$net.result > 0.5, 1,0)\nconfusionMatrix(class_nn, test$diagnosis_result, positive = \"1\")\n\n## max auc that I got after running several times was 0.9642857143\n## accuracy is 0.75\n\n\n# 3. Use one of the classification model that we covered so\n# far. Cross validate it using caret. Out of the two 'cross\n# validated' models, which one is doing better? (20)\n\n## let's use KNN classification algorithm\n\ncancer <- read.csv(\"Cancer.csv\")\nindex <- createDataPartition(cancer$diagnosis_result, p=0.8, list=F)\ntrain_new <- cancer[index,]\ntest_new <- cancer[-index,]\n\nctrl <- trainControl(method = \"repeatedcv\",\n                     number = 10, repeats = 5,\n                     classProbs = TRUE,\n                     summaryFunction = twoClassSummary)\n\nfit_knn <- train(diagnosis_result ~ ., data = train_new, method = \"knn\", \n                 trControl = ctrl, \n                 preProcess = c(\"center\",\"scale\"), \n                 tuneGrid = expand.grid(k = 3:20))\n\nfit_knn$results\nfit_knn$bestTune\n\n## My best k is 8\n\nmodel_knn <- knn(train_new[, -9], test_new[, -9], \n                 train_new$diagnosis_result, \n                 k = 8, prob = T)\n\nprobs <- predict(fit_knn, newdata = test_new, type = 'prob')\np_test_new <- prediction(probs[, 2], test_new$diagnosis_result)\nperformance(p_test_new, \"auc\")@y.values\n\n## AUC for KNN is 0.9687812\n## It is slightly better than neural network on this dataset, most importantly it is more stable\n## neural net's results may vary, while here with a certain k you will get really close results always\n\n# BONUS Find data with at least one catrgorical independent\n# variable and build a neural network on it. What are the\n# AUC, accuracy, sensitivity and specificity of your model?\n# Explain their meanings.  (10)\n\n\n## I used Diabetes dataset from moodle\ndiabetes <- read.csv(\"Diabetes.csv\")\n\nfor(x in 1:8) {\n  diabetes[, x] <- sc(diabetes[, x])\n}\n\nindex <- createDataPartition(diabetes$Class, p=0.8, list=F)\ntrain_diab <- diabetes[index,]\ntest_diab <- diabetes[-index,]\n\nfm <- formula(Class ~ NTS+PGC+DBP+TSFT+INS+BMI+DPF+Age)\n\nmodel_nn_new <- neuralnet(fm, data = train_diab, hidden = c(3, 3), rep = 3,  \n                          linear.output = F, err.fct = \"ce\")\n\nplot(model_nn_new, length = 0.1)\ncmpt_diab <- compute(model_nn_new, test_diab[, -9], rep = 1)\np_test_diab <- ROCR::prediction(cmpt_diab$net.result[, 1], test_diab$Class)\nperformance(p_test_diab, \"auc\")@y.values\n\nclass_nn_diab <- ifelse(cmpt_diab$net.result > 0.5, 1,0)\nconfusionMatrix(class_nn_diab, test_diab$Class, positive = \"1\")\n\n## AUC is 0.810325477\n## accuracy is 0.745098\n## Sensitivity : 0.7037037             \n## Specificity : 0.7676768\n\n## we all know what they mean, don't we? :D",
    "created" : 1481648049691.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "4224108915",
    "id" : "3AB319",
    "lastKnownWriteTime" : 1481648068,
    "last_content_update" : 1481648068578,
    "path" : "D:/Programming/R/Homework 10/Mark_Hovsepyan_HW_10.R",
    "project_path" : "Mark_Hovsepyan_HW_10.R",
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}