{
    "collab_server" : "",
    "contents" : "# The data frame voice contains information about\n# the voices of females and males. It summarizes\n# several measurements for voice and the label,\n# indicating the gender of the 'owner' of the\n# voice.  \n# Do not forget to set the seed to 2016 for\n# all the functions that need random activity.  \n\n## libraries that may be needed\nlibrary(e1071)\nlibrary(caret)\nlibrary(caTools)\nlibrary(ROCR)\nlibrary(klaR)\nlibrary(ggplot2)\nlibrary(class)\nlibrary(MASS)\n\n# 1. Load voice data. Create testing and training\n# sets. 80% goes to train, the rest to test. (7)\n\nvoice <- read.csv(\"voice.csv\")\n\nset.seed(2016)\nindex <- createDataPartition(voice$label, p = 0.8, list = FALSE)\ntrain_voice <- voice[index,]\ntest_voice <- voice[-index,]\n\n# 2. Create svm model, try different types of\n# kernels.  Which one is giving the highest\n# accuracy? Hint: Look at the help of the svm\n# function to see what types of kernels are\n# avilable.(7)\n\n## Kernel types: linear, polynomial, sigmoid, radial basis\n\n## linear kernel\nset.seed(2016)\nmodel_linear <- svm(label ~ ., data = train_voice, kernel = \"linear\", probability = TRUE)\npred_linear <- predict(model_linear, newdata = test_voice, probability = TRUE)\nconfusionMatrix(pred_linear, test_voice$label)\n## Accuracy = 0.9715\n\n## polynomial kernel\nset.seed(2016)\nmodel_polynomial <- svm(label ~ ., data = train_voice, kernel = \"polynomial\", probability = TRUE)\npred_polinomial <- predict(model_polynomial, newdata = test_voice, probability = TRUE)\nconfusionMatrix(pred_polinomial, test_voice$label)\n## Accuracy = 0.9636\n\n## sigmoid kernel\nset.seed(2016)\nmodel_sigmoid <- svm(label ~ ., data = train_voice, kernel = \"sigmoid\", probability = TRUE)\npred_sigmoid <- predict(model_sigmoid, newdata = test_voice, probability = TRUE)\nconfusionMatrix(pred_sigmoid, test_voice$label)\n## Accuracy = 0.7911\n\n## radial basis kernel\nset.seed(2016)\nmodel_radial <- svm(label ~ ., data = train_voice, kernel = \"radial\", probability = TRUE)\npred_radial <- predict(model_radial, newdata = test_voice, probability = TRUE)\nconfusionMatrix(pred_radial, test_voice$label)\n## Accuracy = 0.981\n\n## We get the highest accuracy with radial basis kernel, that is 0.981\n\n\n# 3. Take the type of the kernel that gives the\n# highest accuracy and proceed with it. Plot the\n# ROC taking female as the class of interest. (7)\n\nradial_predict <- predict(model_radial, newdata = test_voice, \n                                  probability = TRUE, type = \"raw\") \nradial_predict <- attr(radial_predict, \"probabilities\")\n\np_test_radial_f <- prediction(radial_predict[,2], test_voice$label, label.ordering = c(\"male\", \"female\"))\nperf_radial_f <- performance(p_test_radial_f, 'tpr', 'fpr')\nplot(perf_radial_f)\n\n# 4. Using library caret, do cross validation and\n# find the optimal value of cost. What is the value\n# of accuracy while using that value of cost? Use the\n# seed of 2016. (8)\n\nset.seed(2016)\nctrl <- trainControl(method = \"repeatedcv\", number = 12, repeats = 4)\n\nset.seed(2016)\nfit_svm <- train(label ~ ., data = train_voice, trControl = ctrl, \n                 method = \"svmRadialCost\", tuneLength = 10)\nfit_svm$results\nfit_svm$bestTune\n\n## The best cost value is 2.0 with accuracy = 0.9809745\n\n# 5. Take any other classification method that we\n# covered during the class.  Compare it to the svm\n# model in terms of accuracy.  Which one does\n# better? (7)\n\n## LDA model\nset.seed(2016)\nLDA_model <- lda(label ~ ., data = train_voice)\nLDA_pred <- predict(LDA_model, newdata = test_voice)\n\nconfusionMatrix(LDA_pred$class, test_voice$label, positive = \"female\")\n\n## Results\n## Accuracy = 0.9636\n## Sensitivity : 0.9589\n## Specificity : 0.9684\n\n## Accuracy of LDA model is worse than of SVM radial kernel model: 0.9636 < 0.981\n\n## GLM model\nset.seed(2016)\nGLM_model <- glm(label ~  ., data = train_voice, family = \"binomial\")\nGLM_pred <- predict(GLM_model, newdata = test_voice, type = \"response\")\n\nlabels <- ifelse(GLM_pred > 0.5, \"male\", \"female\")\nconfusionMatrix(labels, test_voice$label, positive = \"female\")\n\n## Results\n## Accuracy = 0.9699\n## Sensitivity : 0.9810\n## Specificity : 0.9589\n\n## Accuracy of GLM model is worse than of SVM radial kernel model: 0.9699 < 0.981\n\n\n# Diabetes dataset contains information about\n# different characteristics of the patients, as well as\n# if they are diagnosed with diabetes or not.\n\n# 6. Load diabetes.csv into R. Create testing and\n# training datasets. As usual, 80% goes to train,\n# the rest to test.  The proportions of variable\n# Class should be maintained.  Build the lda model\n# on the training set. Report the accuracy of the\n# model.  Use 1 as positive class for diabetes. (7)\n\ndiabetes <- read.csv(\"Diabetes.csv\")\ndiabetes$Class <- as.factor(diabetes$Class)\n\nset.seed(2016)\nindex <- createDataPartition(diabetes$Class, p = 0.8, list = FALSE)\n\ntrain_diab <- diabetes[index,]\ntest_diab <- diabetes[-index,]\n\n## LDA model\nset.seed(2016)\nmodel_lda <- lda(Class ~ . , data = train_diab)\npredict_lda <- predict(model_lda, newdata = test_diab)\nconfusionMatrix(predict_lda$class, test_diab$Class, positive = '1')\n## Accuracy = 0.7516\n\n# 7. Using any of the classification methods that\n# we covered so far, make predictions for the\n# Class. Is that method doing better in comparison\n# with LDA in terms of accuracy? (7)\n\n## SVM radial basis kernel model\nset.seed(2016)\nSVM_radial_model <- svm(Class ~ ., data = train_diab, kernel = \"radial\", probability = TRUE)\nSVM_radial_pred <- predict(SVM_radial_model, newdata = test_diab, probability = TRUE)\n\nconfusionMatrix(SVM_radial_pred, test_diab$Class)\n\n## Results\n## Accuracy = 0.7908\n## Sensitivity : 0.9\n## Specificity : 0.5849\n\n## Accuracy of SVM radial model is better than of LDA model: 0.7908 > 0.7516\n\n## GLM model\nset.seed(2016)\nGLM_model_diab <- glm(Class ~  ., data = train_diab, family = \"binomial\")\nGLM_pred_diab <- predict(GLM_model_diab, newdata = test_diab, type = \"response\")\n\nlabels <- ifelse(GLM_pred_diab > 0.5, \"1\", \"0\")\nconfusionMatrix(labels, test_diab$Class, positive = \"1\")\n\n## Results\n## Accuracy = 0.7647\n## Sensitivity : 0.5849\n## Specificity : 0.86\n\n## Accuracy of GLM model is also slightly better than of LDA model: 0.7647 > 0.7516\n\n# 8. Bonus \n# Find a dataset. Find something\n# interesting related to that data.  Prepare\n# predictive methods, do clustering, find\n# interesting and meaningful patterns based on that\n# data. Do not forget to upload that new data to moodle\n# along with your submission. (10)\n\ngender_data <- read.csv(\"gender_data.csv\")\n\nset.seed(2016)\nindex <- createDataPartition(gender_data$Gender, p = 0.8, list = FALSE)\n\ntrain_gender <- gender_data[index,]\ntest_gender <- gender_data[-index,]\n\n## let's classify this data several methods\n\n## LDA model\nset.seed(2016)\nlda_gender <- lda(Gender ~ . , data = train_gender)\ngender_pred_lda <- predict(lda_gender, newdata = test_gender)\n\nconfusionMatrix(gender_pred_lda$class, test_gender$Gender, positive = 'Female')\n## Accuracy = 0.9195\n\n## SVM polynomial model\nset.seed(2016)\nsvm_gender <- svm(Gender ~ ., data = train_gender, kernel = \"polynomial\", probability = TRUE)\ngender_pred_svm <- predict(svm_gender, newdata = test_gender, probability = TRUE)\n\nconfusionMatrix(gender_pred_svm, test_gender$Gender)\n## Accuracy = 0.9105\n\n## GLM model\nset.seed(2016)\nglm_gender <- glm(Gender ~  ., data = train_gender, family = \"binomial\")\ngender_pred_glm <- predict(glm_gender, newdata = test_gender, type = \"response\")\n\nlabels <- ifelse(gender_pred_glm > 0.5, \"Male\", \"Female\")\nconfusionMatrix(labels, test_gender$Gender, positive = \"Female\")\n## Accuracy = 0.9205\n\n## KNN\nset.seed(2016)\ngender_knn <- knn(train_gender[, 2:3], test_gender[, 2:3], train_gender$Gender, k = 25) # for k = 25\n\nconfusionMatrix(gender_knn, test_gender$Gender, positive = \"Female\")\n## Accuracy = 0.914\n",
    "created" : 1480176257047.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "4124241851",
    "id" : "B3BF7F40",
    "lastKnownWriteTime" : 1480184557,
    "last_content_update" : 1480184557362,
    "path" : "D:/Programming/R/Homework 8/Mark_Hovsepyan_Hw_8.R",
    "project_path" : "Mark_Hovsepyan_Hw_8.R",
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}